{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Akshay Ijantkar\n",
    "### Team: Aqua Wizards\n",
    "### Project: Surfers Bible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://launchschool.com/books/sql/read/table_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRONTAB EXPRESSIONA and STATEMENT:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 2 * * * /usr/bin/python3 /home/ubuntu/pop_db_sch_ss/Daily_Scheduler_Weather_Tide_API.py >> /home/ubuntu/pop_db_sch_ss/log_Daily_Scheduler_Weather_Tide_API.txt 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceback (most recent call last):\n",
    "#   File \"/home/ubuntu/pop_db_sch_ss/Daily_Scheduler_Weather_Tide_API.py\", line 1377, in <module>\n",
    "#     model.load_model('catboost_model_rand_search_tide_weather_shark_feat')\n",
    "#   File \"/home/ubuntu/.local/lib/python3.6/site-packages/catboost/core.py\", line 2589, in load_model\n",
    "#     self._load_model(fname, format)\n",
    "#   File \"/home/ubuntu/.local/lib/python3.6/site-packages/catboost/core.py\", line 1315, in _load_model\n",
    "#     self._object._load_model(model_file, format)\n",
    "#   File \"_catboost.pyx\", line 4658, in _catboost._CatBoost._load_model\n",
    "#   File \"_catboost.pyx\", line 4661, in _catboost._CatBoost._load_model\n",
    "# _catboost.CatBoostError: catboost/libs/model/model_import_interface.h:19: Model file doesn't exist: catboost_model_rand_search_tide_weather_shark_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_Daily_Scheduler_Weather_Tide_API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "# import seaborn as sns; sns.set()\n",
    "# from scipy.stats import norm \n",
    "import matplotlib.pyplot as plt\n",
    "# For Linear regression\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# For split given dataset into train and test set.\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# To verify models using this metrics \n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# import statsmodels.formula.api as smf\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "# v\n",
    "from matplotlib import rcParams\n",
    "# rcParams['figure.figsize'] = 50,50\n",
    "# import pandas_profiling\n",
    "# pd.set_option('display.max_rows', 1500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "\n",
    "# from pygeocoder import Geocoder\n",
    "\n",
    "import sys\n",
    "# from weather_au import api\n",
    "# from weather_au import summary\n",
    "# from weather import place, observations, uv_index\n",
    "import time\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from catboost import CatBoostClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import r2_score\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_validate\n",
    "\n",
    "import catboost as ctb\n",
    "# from catboost import CatBoostRegressor, FeaturesData, Pool\n",
    "# from scipy.stats import uniform as sp_randFloat\n",
    "# from scipy.stats import randint as sp_randInt\n",
    "# from scipy.stats import uniform\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from  sklearn.metrics.pairwise import euclidean_distances\n",
    "# from sklearn.metrics.pairwise import manhattan_distances\n",
    "# from sklearn.metrics.pairwise import pairwise_distances\n",
    "import re\n",
    "import pprint\n",
    "from datetime import date\n",
    "import datetime\n",
    "# import sqlite3\n",
    "# from sqlite3 import Error\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide Date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given_date =  2020-05-18\n",
      "given_date_timestamp_epoch =  1589724000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "no_days_from_today = 3\n",
    "\n",
    "select_date = \"2020-05-18\"\n",
    "\n",
    "if select_date == \"\":    \n",
    "    today = date.today()\n",
    "    today_date = today.strftime(\"%Y-%m-%d\") \n",
    "    given_date =  str((datetime.datetime.strptime(today_date, \"%Y-%m-%d\") + datetime.timedelta(days = no_days_from_today)).date())\n",
    "    given_date_timestamp_epoch = int(time.mktime(time.strptime(given_date, '%Y-%m-%d')))\n",
    "    print(\"today_date = \", today_date)\n",
    "    print(\"given_date = \", given_date)\n",
    "    print(\"given_date_timestamp_epoch = \",given_date_timestamp_epoch)\n",
    "else:\n",
    "    given_date = select_date\n",
    "    given_date_timestamp_epoch = int(time.mktime(time.strptime(given_date, '%Y-%m-%d')))\n",
    "    \n",
    "    print(\"given_date = \", given_date)\n",
    "    print(\"given_date_timestamp_epoch = \",given_date_timestamp_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_5days_lst = []\n",
    "# for day in range(5):\n",
    "#     date_5days_lst.append(str((datetime.datetime.strptime(given_date, \"%Y-%m-%d\") + datetime.timedelta(days = day)).date()))\n",
    "# date_5days_lst    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_epochs_5days_lst = []\n",
    "# for date in date_5days_lst:\n",
    "# #     + 3600\n",
    "#     timestamp_epochs_5days_lst.append(int(time.mktime(time.strptime(date, '%Y-%m-%d'))) )\n",
    "# timestamp_epochs_5days_lst    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ BEACH DATABASE FROM RDS POSTGRES DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as ps\n",
    "\n",
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Beach Table to DF: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beach_df = pd.read_sql_query(\"SELECT * FROM BEACH_TABLE;\", conn)\n",
    "# beach_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beach_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_beach_req_col_lst = ['date',\n",
    " 'beach_id',\n",
    " 'beach_name',\n",
    " 'beach_latitude',\n",
    " 'beach_longitude',\n",
    " 'beach_state',\n",
    " 'time',\n",
    " 'summary',\n",
    " 'icon',\n",
    " 'precipIntensity',\n",
    " 'precipProbability',\n",
    " 'temperature',\n",
    " 'apparentTemperature',\n",
    " 'dewPoint',\n",
    " 'humidity',\n",
    " 'pressure',\n",
    " 'windSpeed',\n",
    " 'windGust',\n",
    " 'windBearing',\n",
    " 'cloudCover',\n",
    " 'uvIndex',\n",
    " 'visibility',\n",
    " 'ozone']\n",
    "\n",
    "weather_df = pd.DataFrame(columns = weather_beach_req_col_lst\n",
    "                         )\n",
    "# weather_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_name =  ADDISCOT BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  0\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3823,144.257,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  1\n",
      "beach_name =  APEX BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  1\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.813,145.547,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  2\n",
      "beach_name =  BACK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  2\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5269,145.37,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  3\n",
      "beach_name =  BANCOORA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  3\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2914,144.407,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  4\n",
      "beach_name =  BARRY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  4\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5176,145.203,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  5\n",
      "beach_name =  BARRYS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  5\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5176,145.203,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  6\n",
      "beach_name =  BAY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  6\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.342,144.749,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  7\n",
      "beach_name =  BELL BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  7\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3688,144.283,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  8\n",
      "beach_name =  BELLS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  8\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3688,144.283,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  9\n",
      "beach_name =  BERRY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  9\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5176,145.203,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  10\n",
      "beach_name =  BETKA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  10\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.5796,149.748,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  11\n",
      "beach_name =  BIDDLES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  11\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7177,143.729,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  12\n",
      "beach_name =  BIRDROCK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  12\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2493,145.028,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  13\n",
      "beach_name =  BIRRELLS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  13\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.923,147.713,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  14\n",
      "beach_name =  BLACK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  14\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5358,145.386,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  15\n",
      "beach_name =  BOOMANGONG BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  15\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8341,145.568,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  16\n",
      "beach_name =  BOUCHIERS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  16\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8383,145.574,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  17\n",
      "beach_name =  BOURKES BEACH NO. 1\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  17\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9768,145.835,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  18\n",
      "beach_name =  BOURKES BEACH NO. 2\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  18\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9757,145.828,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  19\n",
      "beach_name =  BOURKES BEACH NO. 3\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  19\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9795,145.826,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  20\n",
      "beach_name =  BREENS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  20\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8098,145.502,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  21\n",
      "beach_name =  BRENTNALLS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  21\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8492,145.593,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  22\n",
      "beach_name =  BRUCES BEACH NO. 1\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  22\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9658,145.927,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  23\n",
      "beach_name =  BRUCES BEACH NO. 2\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  23\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9655,145.915,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  24\n",
      "beach_name =  BUCHANANS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  24\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9563,145.87,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  25\n",
      "beach_name =  BURGES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  25\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.428,149.714,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  26\n",
      "beach_name =  CABROOGA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  26\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9173,145.678,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  27\n",
      "beach_name =  CARTER BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8218,145.451,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  28\n",
      "beach_name =  CHERRY TREE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  28\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.9856,147.652,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  29\n",
      "beach_name =  CHILDRENS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  29\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5228,145.364,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  30\n",
      "beach_name =  CHINAMAN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  30\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8366,146.419,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  31\n",
      "beach_name =  CHINAMAN LONG BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  31\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8366,146.419,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  32\n",
      "beach_name =  CHINAMANS LONG BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  32\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8366,146.419,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  33\n",
      "beach_name =  CLIFTON BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  33\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6782,143.125,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  34\n",
      "beach_name =  COBRAWONGA BEACH NO. 1\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  34\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9729,145.792,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  35\n",
      "beach_name =  COBRAWONGA BEACH NO. 2\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  35\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9639,145.769,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  36\n",
      "beach_name =  CORNISH BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  36\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9349,145.72,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  37\n",
      "beach_name =  COTTERS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  37\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.9335,146.244,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  38\n",
      "beach_name =  COWRIE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  38\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5095,145.124,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  39\n",
      "beach_name =  CRAIGIE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  39\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2536,145.025,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  40\n",
      "beach_name =  CRUMPETS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  40\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3808,141.641,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  41\n",
      "beach_name =  DARBY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  41\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.9699,146.266,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  42\n",
      "beach_name =  DAVA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  42\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2454,145.028,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  43\n",
      "beach_name =  DAVIS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  43\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8083,145.54,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  44\n",
      "beach_name =  DEAD RIVER BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  44\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8803,145.628,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  45\n",
      "beach_name =  DELRAY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  45\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2435,147.362,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  46\n",
      "beach_name =  DIMMICKS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  46\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3825,144.776,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  47\n",
      "beach_name =  DUFFYS BEACH NO. 1\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  47\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9727,145.832,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  48\n",
      "beach_name =  DUFFYS BEACH NO. 2\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  48\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9767,145.846,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  49\n",
      "beach_name =  EARIMIL BEACH NORTH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  49\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1781,145.076,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  50\n",
      "beach_name =  EARIMIL BEACH SOUTH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  50\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1824,145.074,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  51\n",
      "beach_name =  EAST BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  51\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-36.094,141.969,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  52\n",
      "beach_name =  EASTERN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  52\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8762,148.016,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  53\n",
      "beach_name =  EASTERN BEACH SWIMMING POOL\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  53\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1469,144.373,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  54\n",
      "beach_name =  ELWOOD BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8865,144.981,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  55\n",
      "beach_name =  FARM BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  55\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4893,145.152,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  56\n",
      "beach_name =  FINLEY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  56\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8221,145.559,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  57\n",
      "beach_name =  FISHERMANS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  57\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2256,145.03,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  58\n",
      "beach_name =  FIVE MILE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  58\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.949,146.451,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  59\n",
      "beach_name =  FLAMINGO BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  59\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2827,147.312,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  60\n",
      "beach_name =  FOREST BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  60\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8119,145.51,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  61\n",
      "beach_name =  FORGES BEACH NO. 1\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  61\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9964,145.964,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  62\n",
      "beach_name =  FORGES BEACH NO. 2\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  62\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9928,145.955,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  63\n",
      "beach_name =  FOSSIL BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  63\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2417,145.028,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  64\n",
      "beach_name =  FOSTER BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  64\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6962,146.248,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  65\n",
      "beach_name =  FOSTERS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  65\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2386,145.029,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  66\n",
      "beach_name =  FOUR MILE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  66\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-36.1313,141.933,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  67\n",
      "beach_name =  FRONT BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  67\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3348,144.325,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  68\n",
      "beach_name =  GIBSON BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  68\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6695,143.113,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  69\n",
      "beach_name =  GLENAIRE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  69\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8075,143.462,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  70\n",
      "beach_name =  GLOMAR BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  70\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.29,147.3,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  71\n",
      "beach_name =  GUNNAMATTA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  71\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4587,144.871,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  72\n",
      "beach_name =  HAWKER BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  72\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2569,145.023,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  73\n",
      "beach_name =  HIGH SHORE\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  73\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.5096,149.736,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  74\n",
      "beach_name =  HORSESHOE LAGOON BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  74\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9293,145.697,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  75\n",
      "beach_name =  HUNTS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  75\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8083,145.527,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  76\n",
      "beach_name =  HUTCHINSON BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  76\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5196,145.207,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  77\n",
      "beach_name =  INVERLOCH SURF BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  77\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6462,145.702,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  78\n",
      "beach_name =  JACKS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  78\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3371,145.205,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  79\n",
      "beach_name =  JACKSON BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  79\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8066,148.631,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  80\n",
      "beach_name =  JACKSONS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  80\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8066,148.631,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  81\n",
      "beach_name =  JOHANNA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  81\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7703,143.393,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_name =  KILLARNEY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  82\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3564,142.31,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  83\n",
      "beach_name =  KOONYA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  83\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3541,144.764,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  84\n",
      "beach_name =  KOONYA OCEAN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  84\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3541,144.764,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  85\n",
      "beach_name =  LABBETT BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  85\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8226,145.464,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  86\n",
      "beach_name =  LANG LANG BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  86\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3075,145.521,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  87\n",
      "beach_name =  LANGI OONAH BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  87\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9601,145.778,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  88\n",
      "beach_name =  LAWRENCES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  88\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8302,145.435,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  89\n",
      "beach_name =  LAWSON BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  89\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6921,146.31,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  90\n",
      "beach_name =  LITTLE RIVER BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  90\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3919,142.186,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  91\n",
      "beach_name =  LOGANS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  91\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.404,142.524,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  92\n",
      "beach_name =  LOGANS BEACH WHALE NURSERY\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  92\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4039,142.522,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  93\n",
      "beach_name =  MAIN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  93\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8813,147.996,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  94\n",
      "beach_name =  MAITLAND BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  94\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.891,145.983,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  95\n",
      "beach_name =  MCGAURAN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  95\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4477,147.102,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  96\n",
      "beach_name =  MICKS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  96\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2858,145.291,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  97\n",
      "beach_name =  MILANESIA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  97\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7509,143.316,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  98\n",
      "beach_name =  MILLS BEACH EAST\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  98\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2107,145.049,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  99\n",
      "beach_name =  MILLS BEACH WEST\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  99\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2136,145.044,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  100\n",
      "beach_name =  MOONDAH BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  100\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1872,145.072,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  101\n",
      "beach_name =  MOONLIGHT BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  101\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7487,143.206,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  102\n",
      "beach_name =  MOORES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  102\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8267,145.565,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  103\n",
      "beach_name =  MORGAN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  103\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8658,145.912,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  104\n",
      "beach_name =  MORGANS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  104\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8658,145.912,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  105\n",
      "beach_name =  MOTHERS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  105\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2149,145.035,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  106\n",
      "beach_name =  MOTS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  106\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.7976,148.561,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  107\n",
      "beach_name =  MOUNT MARTHA BEACH NORTH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  107\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2623,145.017,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  108\n",
      "beach_name =  MOUNT MARTHA BEACH SOUTH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  108\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2706,145.007,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_name =  MULBERRY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  109\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8184,145.559,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  110\n",
      "beach_name =  MYRONG BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  110\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-36.1206,143.732,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  111\n",
      "beach_name =  NETTLE PASS\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  111\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7539,143.322,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  112\n",
      "beach_name =  NEVINS BEACH EAST\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  112\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9545,145.892,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  113\n",
      "beach_name =  NINETY MILE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  113\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.0861,147.569,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  114\n",
      "beach_name =  NO. 16 BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  114\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3935,144.792,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  115\n",
      "beach_name =  NORMAN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  115\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-39.0368,146.322,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  116\n",
      "beach_name =  NUDE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  116\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.4405,149.707,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  117\n",
      "beach_name =  NUNS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  117\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3428,141.608,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  118\n",
      "beach_name =  OCEAN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  118\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4817,145.016,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  119\n",
      "beach_name =  OLD SETTLEMENT BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  119\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6573,146.668,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  120\n",
      "beach_name =  PADDYS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  120\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9262,145.703,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  121\n",
      "beach_name =  PEARSES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  121\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3805,144.774,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  122\n",
      "beach_name =  PEBBLY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  122\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8151,145.563,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  123\n",
      "beach_name =  PEPPERTREE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  123\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8293,145.419,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  124\n",
      "beach_name =  PETTMANS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  124\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8295,148.189,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  125\n",
      "beach_name =  PICNIC BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  125\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.715,146.668,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  126\n",
      "beach_name =  POINT LEO BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  126\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4192,145.078,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  127\n",
      "beach_name =  POINT LEO SURF BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  127\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4249,145.071,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  128\n",
      "beach_name =  PORTSEA SURF BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  128\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3371,144.709,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  129\n",
      "beach_name =  PRINCETOWN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  129\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7071,143.159,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  130\n",
      "beach_name =  PUMPHOUSE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  130\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9584,145.757,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  131\n",
      "beach_name =  QUARRY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  131\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.5995,149.731,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  132\n",
      "beach_name =  QUICKS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  132\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.926,145.698,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  133\n",
      "beach_name =  RANELAGH BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  133\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1769,145.077,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  134\n",
      "beach_name =  RED BLUFF BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  134\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8093,146.24,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  135\n",
      "beach_name =  REDBANK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  135\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9599,145.854,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_name =  REEVES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  136\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5752,146.954,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  137\n",
      "beach_name =  RICARDO BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  137\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8061,148.62,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  138\n",
      "beach_name =  RIPPLESIDE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  138\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1291,144.357,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  139\n",
      "beach_name =  RIVERNOOK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  139\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.717,143.169,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  140\n",
      "beach_name =  ROBERTSONS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  140\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6598,146.73,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  141\n",
      "beach_name =  ROYAL BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  141\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2175,145.033,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  142\n",
      "beach_name =  RYE OCEAN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  142\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4187,144.824,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  143\n",
      "beach_name =  SAFETY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  143\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3214,144.983,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  144\n",
      "beach_name =  SAINT ANDREWS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  144\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4271,144.835,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  145\n",
      "beach_name =  SAINT HELENS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  145\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1203,144.36,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  146\n",
      "beach_name =  SAINT PAULS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  146\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3533,144.736,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  147\n",
      "beach_name =  SALMON BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  147\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.8081,148.726,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  148\n",
      "beach_name =  SANDRIDGE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  148\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.84,144.917,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  149\n",
      "beach_name =  SANDY WATERHOLE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  149\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5432,145.444,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  150\n",
      "beach_name =  SCOTTS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  150\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9265,145.677,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  151\n",
      "beach_name =  SCOUT BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  151\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2147,145.038,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  152\n",
      "beach_name =  SECRET BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  152\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.6088,149.721,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  153\n",
      "beach_name =  SHELLEY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  153\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3599,141.44,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  154\n",
      "beach_name =  SHELLY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  154\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5518,143.985,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  155\n",
      "beach_name =  SHIRE HALL BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  155\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2141,145.04,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  156\n",
      "beach_name =  SHOREHAM BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  156\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4362,145.046,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  157\n",
      "beach_name =  SMITH BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  157\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.504,145.255,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  158\n",
      "beach_name =  SMITHS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  158\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.504,145.255,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  159\n",
      "beach_name =  SOMERS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  159\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3952,145.162,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  160\n",
      "beach_name =  SORRENTO BACK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  160\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3469,144.728,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  161\n",
      "beach_name =  SORRENTO FRONT BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  161\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.342,144.749,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  162\n",
      "beach_name =  SOUTH BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  162\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.7457,142.841,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_name =  SOUTHCOMBE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  163\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3922,142.231,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  164\n",
      "beach_name =  SQUEAKY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  164\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-39.0253,146.305,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  165\n",
      "beach_name =  ST ANDREWS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  165\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.4271,144.835,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  166\n",
      "beach_name =  ST HELENS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  166\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1203,144.36,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  167\n",
      "beach_name =  ST PAULS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  167\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3533,144.736,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  168\n",
      "beach_name =  STATION BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  168\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8295,143.485,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  169\n",
      "beach_name =  STEELES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  169\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.4555,149.695,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  170\n",
      "beach_name =  SUNNYSIDE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  170\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2003,145.063,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  171\n",
      "beach_name =  SUTHERLANDS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  171\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7563,143.361,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  172\n",
      "beach_name =  TAYLORS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  172\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3902,142.172,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  173\n",
      "beach_name =  TEACHERS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  173\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8024,145.535,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  174\n",
      "beach_name =  THE MAHOGANYS\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  174\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.7754,148.98,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  175\n",
      "beach_name =  THE WRECK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  175\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2535,147.349,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  176\n",
      "beach_name =  THIRTEENTH BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  176\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.2845,144.459,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  177\n",
      "beach_name =  THOMSONS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  177\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9128,145.667,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  178\n",
      "beach_name =  THORNY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  178\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5132,145.182,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  179\n",
      "beach_name =  THREE MILE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  179\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8647,146.468,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  180\n",
      "beach_name =  TIP BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  180\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-37.5739,149.759,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  181\n",
      "beach_name =  TOORA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  181\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.6913,146.336,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  182\n",
      "beach_name =  TRUES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  182\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.9584,145.908,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  183\n",
      "beach_name =  TURRAS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  183\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1622,146.314,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  184\n",
      "beach_name =  ULUPNA BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  184\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8153,145.524,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  185\n",
      "beach_name =  WEISS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  185\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8614,145.597,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  186\n",
      "beach_name =  WESTERN BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  186\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1363,144.356,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  187\n",
      "beach_name =  WESTERN PARK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  187\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.398,145.184,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  188\n",
      "beach_name =  WHITES BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  188\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3205,144.34,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  189\n",
      "beach_name =  WILD DOG BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  189\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.03,141.14,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_name =  WILD DOG SHORE\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  190\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.1328,147.339,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  191\n",
      "beach_name =  WILLOW BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  191\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8488,145.584,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  192\n",
      "beach_name =  WILSONS BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  192\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.8688,145.602,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  193\n",
      "beach_name =  WOODSIDE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  193\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5522,146.978,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  194\n",
      "beach_name =  WOOLAMAI SURF BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  194\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.5389,145.333,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  195\n",
      "beach_name =  WOOLLEY BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  195\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.3466,145.218,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  196\n",
      "beach_name =  WRECK BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  196\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.7546,143.212,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  197\n",
      "beach_name =  YANAKIE BEACH\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  197\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-38.8108,146.269,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  198\n",
      "beach_name =  ZINETTIS BEACH NO. 1\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  198\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.967,145.941,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  199\n",
      "beach_name =  ZINETTIS BEACH NO. 2\n",
      "date =  2020-05-18 \n",
      "\n",
      "index =  199\n",
      "get_request =  https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-35.97,145.936,1589724000\n",
      "****************************************************************************************************\n",
      "cnt =>>>>>>>>>>>>>>>>>>>>>  200\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# Wall time: 24min 24s\n",
    "API_KEY = \"bdbb908566b674b2e5971ac7f61e1bfc\"\n",
    "cnt = 0\n",
    "# https://api.darksky.net/forecast/bdbb908566b674b2e5971ac7f61e1bfc/-33.869,151.209,2019-12-30T12:00:00\n",
    "\n",
    "# for date in date_5days_lst[:]:\n",
    "    \n",
    "#     timestamp_epochs = int(time.mktime(time.strptime(date, '%Y-%m-%d')))\n",
    "\n",
    "for index, row in beach_df.loc[:,].iterrows():\n",
    "\n",
    "    print(\"beach_name = \", row[\"beach_name\"])\n",
    "    print(\"date = \",given_date,\"\\n\")\n",
    "    print(\"index = \", index)\n",
    "\n",
    "    get_request = \"\"\n",
    "    get_request += \"https://api.darksky.net/forecast/\"\n",
    "    get_request += API_KEY\n",
    "    get_request += \"/\"\n",
    "    get_request += str(row[\"beach_latitude\"])\n",
    "    get_request += \",\"\n",
    "    get_request += str(row[\"beach_longitude\"])\n",
    "    get_request += \",\"\n",
    "    get_request += str(given_date_timestamp_epoch)\n",
    "\n",
    "    response_dict = json.loads(requests.get(get_request).text)\n",
    "\n",
    "    print(\"get_request = \", get_request)\n",
    "    print(\"****************************************************************************************************\")\n",
    "#     print(\"response_dict = \",response_dict)\n",
    "\n",
    "    if len(list(response_dict.keys())) > 2:\n",
    "        cnt = cnt + 1\n",
    "        print(\"cnt =>>>>>>>>>>>>>>>>>>>>> \", cnt)\n",
    "\n",
    "        weather_row_dict = {}\n",
    "\n",
    "        for per_hr_attri_dict in response_dict['hourly']['data']:\n",
    "\n",
    "            weather_row_dict[\"date\"] = given_date\n",
    "\n",
    "            for col in ['beach_id', 'beach_name', 'beach_latitude', 'beach_longitude', 'beach_state']:\n",
    "                weather_row_dict[col] = row[col]\n",
    "\n",
    "            for hr_attri in per_hr_attri_dict.keys():\n",
    "                weather_row_dict[hr_attri] = per_hr_attri_dict[hr_attri]                    \n",
    "\n",
    "            weather_row_dict[\"nearest-station\"] = response_dict['flags']['nearest-station']\n",
    "            weather_row_dict[\"sources\"] = response_dict['flags']['sources']\n",
    "            weather_row_dict[\"offset\"] = response_dict['offset']            \n",
    "\n",
    "            weather_df = weather_df.append(weather_row_dict, ignore_index=True)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"############################################################################################\")\n",
    "        print(\"Response Failed...!\")\n",
    "        print(\"beach_name = \", row[\"beach_name\"])\n",
    "        print(\"date = \",date,\"\\n\")\n",
    "        print(\"index = \", index)\n",
    "        print(\"############################################################################################\")\n",
    "#     time.sleep(1)\n",
    "# weather_df            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert timestamp epochs to datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[\"datetime\"] = weather_df[\"time\"].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://launchschool.com/books/sql/read/table_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as ps\n",
    "\n",
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_table_query = '''\n",
    "      CREATE TABLE IF NOT EXISTS WEATHER_TABLE\n",
    "      (\n",
    "        weather_id SERIAL PRIMARY KEY,\n",
    "        date DATE,\n",
    "        beach_id INTEGER NOT NULL,\n",
    "        beach_name TEXT,\n",
    "        beach_latitude REAL,\n",
    "        beach_longitude REAL,\n",
    "        beach_state TEXT,\n",
    "        time REAL,\n",
    "        summary TEXT,\n",
    "        icon TEXT,\n",
    "        precipIntensity REAL,\n",
    "        precipProbability REAL,\n",
    "        temperature REAL,\n",
    "        apparentTemperature REAL,\n",
    "        dewPoint REAL,\n",
    "        humidity REAL,\n",
    "        pressure REAL,\n",
    "        windSpeed REAL,\n",
    "        windGust REAL,\n",
    "        windBearing REAL,\n",
    "        cloudCover REAL,\n",
    "        uvIndex REAL,\n",
    "        visibility REAL,\n",
    "        ozone REAL,\n",
    "        nearest_station REAL,\n",
    "        time_offset REAL,\n",
    "        precipType TEXT,\n",
    "        sources TEXT,\n",
    "        datetime TEXT,\n",
    "        FOREIGN KEY (beach_id) REFERENCES beach_table(beach_id) ON DELETE CASCADE\n",
    "       ); \n",
    "       '''\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Wall time: 12min 16s\n",
    "import psycopg2 as ps\n",
    "\n",
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "fill_question_mark_str = str(tuple([\"%s\"  for i in weather_df.columns.tolist()])).replace(\"'\", \"\")\n",
    "fill_question_mark_str\n",
    "\n",
    "for row in weather_df.itertuples():\n",
    "    data_tuple = tuple(row[1:])\n",
    "\n",
    "#     print(\"data_tuple = \", data_tuple)\n",
    "#     print(\" \")\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "                        INSERT INTO WEATHER_TABLE\n",
    "                        (\n",
    "                            date,\n",
    "                            beach_id,\n",
    "                            beach_name,\n",
    "                            beach_latitude,\n",
    "                            beach_longitude,\n",
    "                            beach_state,\n",
    "                            time,\n",
    "                            summary,\n",
    "                            icon,\n",
    "                            precipIntensity,\n",
    "                            precipProbability,\n",
    "                            temperature,\n",
    "                            apparentTemperature,\n",
    "                            dewPoint,\n",
    "                            humidity,\n",
    "                            pressure,\n",
    "                            windSpeed,\n",
    "                            windGust,\n",
    "                            windBearing,\n",
    "                            cloudCover,\n",
    "                            uvIndex,\n",
    "                            visibility,\n",
    "                            ozone,\n",
    "                            nearest_station,\n",
    "                            time_offset,\n",
    "                            precipType,\n",
    "                            sources,\n",
    "                            datetime\n",
    "                         ) VALUES  \n",
    "                         \"\"\" + fill_question_mark_str + \" ;\"\n",
    "                , data_tuple)    \n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[\"date_beach_name\"] = weather_df[\n",
    "                                                ['date', 'beach_name']\n",
    "                                             ].apply(lambda x: '|'.join(x.astype(str).values), axis=1)\n",
    "# weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# weather_df.to_csv(log_dataset_path + \"weather_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGGREGATE WEATHER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ops_lst = ['max','min','mean','median','std','var','sem']\n",
    "weather_numeric_features = [\"temperature\", \"apparentTemperature\", \"dewPoint\", \"humidity\", \"windSpeed\", \"windBearing\", \"uvIndex\",\n",
    "                    \"cloudCover\"]\n",
    "\n",
    "agg_dict = dict(zip(weather_numeric_features, [agg_ops_lst for i in range(len(weather_numeric_features))]))\n",
    "# agg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weather_numeric_features:\n",
    "    weather_df[col] = weather_df[col].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_weather_df.shape =  (200, 62)\n"
     ]
    }
   ],
   "source": [
    "weather_beach_req_col_lst = [\n",
    "    \"date_beach_name\",\n",
    "    'date',\n",
    "     'beach_name',\n",
    "     'beach_latitude',\n",
    "     'beach_longitude',\n",
    "     'beach_state',\n",
    "]\n",
    "\n",
    "agg_weather_df = weather_df[weather_numeric_features + [\"date_beach_name\"]].groupby('date_beach_name').agg(agg_dict)\n",
    "\n",
    "agg_weather_df.columns = [\"_\".join(x) for x in agg_weather_df.columns.ravel()]\n",
    "agg_weather_df.reset_index(level=0, inplace=True)\n",
    "agg_weather_df =  pd.merge(\n",
    "                           agg_weather_df, \n",
    "                           weather_df[weather_beach_req_col_lst],\n",
    "                           left_on = \"date_beach_name\",\n",
    "                           right_on = \"date_beach_name\",\n",
    "                           how = \"inner\"\n",
    "                            )\n",
    "\n",
    "agg_weather_df.drop_duplicates(inplace = True)\n",
    "agg_weather_df.reset_index(inplace = True, \n",
    "                           drop = True)\n",
    "\n",
    "print(\"agg_weather_df.shape = \", agg_weather_df.shape)\n",
    "# agg_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# agg_weather_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# agg_weather_df.to_csv(log_dataset_path + \"agg_weather_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF WEATHER API PROCESSING:\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIDE API PROCESSING STARTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_tide_df = pd.DataFrame(columns = [\n",
    "                                         'date',\n",
    "                                        'beach_id',\n",
    "                                        'beach_name',\n",
    "                                        'beach_latitude',\n",
    "                                        'beach_longitude',\n",
    "                                        'beach_state',\n",
    "                                         'timestamp', \n",
    "                                         'datetime', \n",
    "                                         'height', \n",
    "                                         'state', \n",
    "                                         'origin_distance',\n",
    "                                         \"origin_distance_unit\", \n",
    "                                         \"origin_latitude\", \n",
    "                                         \"origin_longitude\", \n",
    "                                         \"timezone\"\n",
    "                                        ]\n",
    "                              )\n",
    "\n",
    "# heights_tide_df \n",
    "extremes_tide_df = pd.DataFrame(columns = [\n",
    "                                        'date',\n",
    "                                        'beach_id',\n",
    "                                        'beach_name',\n",
    "                                        'beach_latitude',\n",
    "                                        'beach_longitude',\n",
    "                                        'beach_state',   \n",
    "                                        'timestamp', \n",
    "                                        'datetime', \n",
    "                                        'height', \n",
    "                                        'state'\n",
    "                                          ]\n",
    "                               )\n",
    "\n",
    "# extremes_tide_df\n",
    "datum_tide_df = pd.DataFrame(columns = [\n",
    "                                        'date',\n",
    "                                        'beach_id',\n",
    "                                        'beach_name',\n",
    "                                        'beach_latitude',\n",
    "                                        'beach_longitude',\n",
    "                                        'beach_state',                \n",
    "                                        'timestamp', \n",
    "                                        'datetime', \n",
    "                                        'datum', \n",
    "                                        'LAT', \n",
    "                                        'HAT'\n",
    "                                        ]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_name =  ADDISCOT BEACH\n",
      "index =  0\n",
      " \n",
      "cnt =  1\n",
      " \n",
      "beach_name =  APEX BEACH\n",
      "index =  1\n",
      " \n",
      "cnt =  2\n",
      " \n",
      "beach_name =  BACK BEACH\n",
      "index =  2\n",
      " \n",
      "cnt =  3\n",
      " \n",
      "beach_name =  BANCOORA BEACH\n",
      "index =  3\n",
      " \n",
      "cnt =  4\n",
      " \n",
      "beach_name =  BARRY BEACH\n",
      "index =  4\n",
      " \n",
      "cnt =  5\n",
      " \n",
      "beach_name =  BARRYS BEACH\n",
      "index =  5\n",
      " \n",
      "cnt =  6\n",
      " \n",
      "beach_name =  BAY BEACH\n",
      "index =  6\n",
      " \n",
      "cnt =  7\n",
      " \n",
      "beach_name =  BELL BEACH\n",
      "index =  7\n",
      " \n",
      "cnt =  8\n",
      " \n",
      "beach_name =  BELLS BEACH\n",
      "index =  8\n",
      " \n",
      "cnt =  9\n",
      " \n",
      "beach_name =  BERRY BEACH\n",
      "index =  9\n",
      " \n",
      "cnt =  10\n",
      " \n",
      "beach_name =  BETKA BEACH\n",
      "index =  10\n",
      " \n",
      "cnt =  11\n",
      " \n",
      "beach_name =  BIDDLES BEACH\n",
      "index =  11\n",
      " \n",
      "cnt =  12\n",
      " \n",
      "beach_name =  BIRDROCK BEACH\n",
      "index =  12\n",
      " \n",
      "cnt =  13\n",
      " \n",
      "beach_name =  BIRRELLS BEACH\n",
      "index =  13\n",
      " \n",
      "cnt =  14\n",
      " \n",
      "beach_name =  BLACK BEACH\n",
      "index =  14\n",
      " \n",
      "cnt =  15\n",
      " \n",
      "beach_name =  BOOMANGONG BEACH\n",
      "index =  15\n",
      " \n",
      "cnt =  16\n",
      " \n",
      "beach_name =  BOUCHIERS BEACH\n",
      "index =  16\n",
      " \n",
      "cnt =  17\n",
      " \n",
      "beach_name =  BOURKES BEACH NO. 1\n",
      "index =  17\n",
      " \n",
      "cnt =  18\n",
      " \n",
      "beach_name =  BOURKES BEACH NO. 2\n",
      "index =  18\n",
      " \n",
      "cnt =  19\n",
      " \n",
      "beach_name =  BOURKES BEACH NO. 3\n",
      "index =  19\n",
      " \n",
      "cnt =  20\n",
      " \n",
      "beach_name =  BREENS BEACH\n",
      "index =  20\n",
      " \n",
      "cnt =  21\n",
      " \n",
      "beach_name =  BRENTNALLS BEACH\n",
      "index =  21\n",
      " \n",
      "cnt =  22\n",
      " \n",
      "beach_name =  BRUCES BEACH NO. 1\n",
      "index =  22\n",
      " \n",
      "cnt =  23\n",
      " \n",
      "beach_name =  BRUCES BEACH NO. 2\n",
      "index =  23\n",
      " \n",
      "cnt =  24\n",
      " \n",
      "beach_name =  BUCHANANS BEACH\n",
      "index =  24\n",
      " \n",
      "cnt =  25\n",
      " \n",
      "beach_name =  BURGES BEACH\n",
      "index =  25\n",
      " \n",
      "cnt =  26\n",
      " \n",
      "beach_name =  CABROOGA BEACH\n",
      "index =  26\n",
      " \n",
      "cnt =  27\n",
      " \n",
      "beach_name =  CARTER BEACH\n",
      "index =  27\n",
      " \n",
      "cnt =  28\n",
      " \n",
      "beach_name =  CHERRY TREE BEACH\n",
      "index =  28\n",
      " \n",
      "cnt =  29\n",
      " \n",
      "beach_name =  CHILDRENS BEACH\n",
      "index =  29\n",
      " \n",
      "cnt =  30\n",
      " \n",
      "beach_name =  CHINAMAN BEACH\n",
      "index =  30\n",
      " \n",
      "cnt =  31\n",
      " \n",
      "beach_name =  CHINAMAN LONG BEACH\n",
      "index =  31\n",
      " \n",
      "cnt =  32\n",
      " \n",
      "beach_name =  CHINAMANS LONG BEACH\n",
      "index =  32\n",
      " \n",
      "cnt =  33\n",
      " \n",
      "beach_name =  CLIFTON BEACH\n",
      "index =  33\n",
      " \n",
      "cnt =  34\n",
      " \n",
      "beach_name =  COBRAWONGA BEACH NO. 1\n",
      "index =  34\n",
      " \n",
      "cnt =  35\n",
      " \n",
      "beach_name =  COBRAWONGA BEACH NO. 2\n",
      "index =  35\n",
      " \n",
      "cnt =  36\n",
      " \n",
      "beach_name =  CORNISH BEACH\n",
      "index =  36\n",
      " \n",
      "cnt =  37\n",
      " \n",
      "beach_name =  COTTERS BEACH\n",
      "index =  37\n",
      " \n",
      "cnt =  38\n",
      " \n",
      "beach_name =  COWRIE BEACH\n",
      "index =  38\n",
      " \n",
      "cnt =  39\n",
      " \n",
      "beach_name =  CRAIGIE BEACH\n",
      "index =  39\n",
      " \n",
      "cnt =  40\n",
      " \n",
      "beach_name =  CRUMPETS BEACH\n",
      "index =  40\n",
      " \n",
      "cnt =  41\n",
      " \n",
      "beach_name =  DARBY BEACH\n",
      "index =  41\n",
      " \n",
      "cnt =  42\n",
      " \n",
      "beach_name =  DAVA BEACH\n",
      "index =  42\n",
      " \n",
      "cnt =  43\n",
      " \n",
      "beach_name =  DAVIS BEACH\n",
      "index =  43\n",
      " \n",
      "cnt =  44\n",
      " \n",
      "beach_name =  DEAD RIVER BEACH\n",
      "index =  44\n",
      " \n",
      "cnt =  45\n",
      " \n",
      "beach_name =  DELRAY BEACH\n",
      "index =  45\n",
      " \n",
      "cnt =  46\n",
      " \n",
      "beach_name =  DIMMICKS BEACH\n",
      "index =  46\n",
      " \n",
      "cnt =  47\n",
      " \n",
      "beach_name =  DUFFYS BEACH NO. 1\n",
      "index =  47\n",
      " \n",
      "cnt =  48\n",
      " \n",
      "beach_name =  DUFFYS BEACH NO. 2\n",
      "index =  48\n",
      " \n",
      "cnt =  49\n",
      " \n",
      "beach_name =  EARIMIL BEACH NORTH\n",
      "index =  49\n",
      " \n",
      "cnt =  50\n",
      " \n",
      "beach_name =  EARIMIL BEACH SOUTH\n",
      "index =  50\n",
      " \n",
      "cnt =  51\n",
      " \n",
      "beach_name =  EAST BEACH\n",
      "index =  51\n",
      " \n",
      "cnt =  52\n",
      " \n",
      "beach_name =  EASTERN BEACH\n",
      "index =  52\n",
      " \n",
      "cnt =  53\n",
      " \n",
      "beach_name =  EASTERN BEACH SWIMMING POOL\n",
      "index =  53\n",
      " \n",
      "cnt =  54\n",
      " \n",
      "beach_name =  ELWOOD BEACH\n",
      "index =  54\n",
      " \n",
      "cnt =  55\n",
      " \n",
      "beach_name =  FARM BEACH\n",
      "index =  55\n",
      " \n",
      "cnt =  56\n",
      " \n",
      "beach_name =  FINLEY BEACH\n",
      "index =  56\n",
      " \n",
      "cnt =  57\n",
      " \n",
      "beach_name =  FISHERMANS BEACH\n",
      "index =  57\n",
      " \n",
      "cnt =  58\n",
      " \n",
      "beach_name =  FIVE MILE BEACH\n",
      "index =  58\n",
      " \n",
      "cnt =  59\n",
      " \n",
      "beach_name =  FLAMINGO BEACH\n",
      "index =  59\n",
      " \n",
      "cnt =  60\n",
      " \n",
      "beach_name =  FOREST BEACH\n",
      "index =  60\n",
      " \n",
      "cnt =  61\n",
      " \n",
      "beach_name =  FORGES BEACH NO. 1\n",
      "index =  61\n",
      " \n",
      "cnt =  62\n",
      " \n",
      "beach_name =  FORGES BEACH NO. 2\n",
      "index =  62\n",
      " \n",
      "cnt =  63\n",
      " \n",
      "beach_name =  FOSSIL BEACH\n",
      "index =  63\n",
      " \n",
      "cnt =  64\n",
      " \n",
      "beach_name =  FOSTER BEACH\n",
      "index =  64\n",
      " \n",
      "cnt =  65\n",
      " \n",
      "beach_name =  FOSTERS BEACH\n",
      "index =  65\n",
      " \n",
      "cnt =  66\n",
      " \n",
      "beach_name =  FOUR MILE BEACH\n",
      "index =  66\n",
      " \n",
      "cnt =  67\n",
      " \n",
      "beach_name =  FRONT BEACH\n",
      "index =  67\n",
      " \n",
      "cnt =  68\n",
      " \n",
      "beach_name =  GIBSON BEACH\n",
      "index =  68\n",
      " \n",
      "cnt =  69\n",
      " \n",
      "beach_name =  GLENAIRE BEACH\n",
      "index =  69\n",
      " \n",
      "cnt =  70\n",
      " \n",
      "beach_name =  GLOMAR BEACH\n",
      "index =  70\n",
      " \n",
      "cnt =  71\n",
      " \n",
      "beach_name =  GUNNAMATTA BEACH\n",
      "index =  71\n",
      " \n",
      "cnt =  72\n",
      " \n",
      "beach_name =  HAWKER BEACH\n",
      "index =  72\n",
      " \n",
      "cnt =  73\n",
      " \n",
      "beach_name =  HIGH SHORE\n",
      "index =  73\n",
      " \n",
      "cnt =  74\n",
      " \n",
      "beach_name =  HORSESHOE LAGOON BEACH\n",
      "index =  74\n",
      " \n",
      "cnt =  75\n",
      " \n",
      "beach_name =  HUNTS BEACH\n",
      "index =  75\n",
      " \n",
      "cnt =  76\n",
      " \n",
      "beach_name =  HUTCHINSON BEACH\n",
      "index =  76\n",
      " \n",
      "cnt =  77\n",
      " \n",
      "beach_name =  INVERLOCH SURF BEACH\n",
      "index =  77\n",
      " \n",
      "cnt =  78\n",
      " \n",
      "beach_name =  JACKS BEACH\n",
      "index =  78\n",
      " \n",
      "cnt =  79\n",
      " \n",
      "beach_name =  JACKSON BEACH\n",
      "index =  79\n",
      " \n",
      "cnt =  80\n",
      " \n",
      "beach_name =  JACKSONS BEACH\n",
      "index =  80\n",
      " \n",
      "cnt =  81\n",
      " \n",
      "beach_name =  JOHANNA BEACH\n",
      "index =  81\n",
      " \n",
      "cnt =  82\n",
      " \n",
      "beach_name =  KILLARNEY BEACH\n",
      "index =  82\n",
      " \n",
      "cnt =  83\n",
      " \n",
      "beach_name =  KOONYA BEACH\n",
      "index =  83\n",
      " \n",
      "cnt =  84\n",
      " \n",
      "beach_name =  KOONYA OCEAN BEACH\n",
      "index =  84\n",
      " \n",
      "cnt =  85\n",
      " \n",
      "beach_name =  LABBETT BEACH\n",
      "index =  85\n",
      " \n",
      "cnt =  86\n",
      " \n",
      "beach_name =  LANG LANG BEACH\n",
      "index =  86\n",
      " \n",
      "cnt =  87\n",
      " \n",
      "beach_name =  LANGI OONAH BEACH\n",
      "index =  87\n",
      " \n",
      "cnt =  88\n",
      " \n",
      "beach_name =  LAWRENCES BEACH\n",
      "index =  88\n",
      " \n",
      "cnt =  89\n",
      " \n",
      "beach_name =  LAWSON BEACH\n",
      "index =  89\n",
      " \n",
      "cnt =  90\n",
      " \n",
      "beach_name =  LITTLE RIVER BEACH\n",
      "index =  90\n",
      " \n",
      "cnt =  91\n",
      " \n",
      "beach_name =  LOGANS BEACH\n",
      "index =  91\n",
      " \n",
      "cnt =  92\n",
      " \n",
      "beach_name =  LOGANS BEACH WHALE NURSERY\n",
      "index =  92\n",
      " \n",
      "cnt =  93\n",
      " \n",
      "beach_name =  MAIN BEACH\n",
      "index =  93\n",
      " \n",
      "cnt =  94\n",
      " \n",
      "beach_name =  MAITLAND BEACH\n",
      "index =  94\n",
      " \n",
      "cnt =  95\n",
      " \n",
      "beach_name =  MCGAURAN BEACH\n",
      "index =  95\n",
      " \n",
      "cnt =  96\n",
      " \n",
      "beach_name =  MICKS BEACH\n",
      "index =  96\n",
      " \n",
      "cnt =  97\n",
      " \n",
      "beach_name =  MILANESIA BEACH\n",
      "index =  97\n",
      " \n",
      "cnt =  98\n",
      " \n",
      "beach_name =  MILLS BEACH EAST\n",
      "index =  98\n",
      " \n",
      "cnt =  99\n",
      " \n",
      "beach_name =  MILLS BEACH WEST\n",
      "index =  99\n",
      " \n",
      "cnt =  100\n",
      " \n",
      "beach_name =  MOONDAH BEACH\n",
      "index =  100\n",
      " \n",
      "cnt =  101\n",
      " \n",
      "beach_name =  MOONLIGHT BEACH\n",
      "index =  101\n",
      " \n",
      "cnt =  102\n",
      " \n",
      "beach_name =  MOORES BEACH\n",
      "index =  102\n",
      " \n",
      "cnt =  103\n",
      " \n",
      "beach_name =  MORGAN BEACH\n",
      "index =  103\n",
      " \n",
      "cnt =  104\n",
      " \n",
      "beach_name =  MORGANS BEACH\n",
      "index =  104\n",
      " \n",
      "cnt =  105\n",
      " \n",
      "beach_name =  MOTHERS BEACH\n",
      "index =  105\n",
      " \n",
      "cnt =  106\n",
      " \n",
      "beach_name =  MOTS BEACH\n",
      "index =  106\n",
      " \n",
      "cnt =  107\n",
      " \n",
      "beach_name =  MOUNT MARTHA BEACH NORTH\n",
      "index =  107\n",
      " \n",
      "cnt =  108\n",
      " \n",
      "beach_name =  MOUNT MARTHA BEACH SOUTH\n",
      "index =  108\n",
      " \n",
      "cnt =  109\n",
      " \n",
      "beach_name =  MULBERRY BEACH\n",
      "index =  109\n",
      " \n",
      "cnt =  110\n",
      " \n",
      "beach_name =  MYRONG BEACH\n",
      "index =  110\n",
      " \n",
      "cnt =  111\n",
      " \n",
      "beach_name =  NETTLE PASS\n",
      "index =  111\n",
      " \n",
      "cnt =  112\n",
      " \n",
      "beach_name =  NEVINS BEACH EAST\n",
      "index =  112\n",
      " \n",
      "cnt =  113\n",
      " \n",
      "beach_name =  NINETY MILE BEACH\n",
      "index =  113\n",
      " \n",
      "cnt =  114\n",
      " \n",
      "beach_name =  NO. 16 BEACH\n",
      "index =  114\n",
      " \n",
      "cnt =  115\n",
      " \n",
      "beach_name =  NORMAN BEACH\n",
      "index =  115\n",
      " \n",
      "cnt =  116\n",
      " \n",
      "beach_name =  NUDE BEACH\n",
      "index =  116\n",
      " \n",
      "cnt =  117\n",
      " \n",
      "beach_name =  NUNS BEACH\n",
      "index =  117\n",
      " \n",
      "cnt =  118\n",
      " \n",
      "beach_name =  OCEAN BEACH\n",
      "index =  118\n",
      " \n",
      "cnt =  119\n",
      " \n",
      "beach_name =  OLD SETTLEMENT BEACH\n",
      "index =  119\n",
      " \n",
      "cnt =  120\n",
      " \n",
      "beach_name =  PADDYS BEACH\n",
      "index =  120\n",
      " \n",
      "cnt =  121\n",
      " \n",
      "beach_name =  PEARSES BEACH\n",
      "index =  121\n",
      " \n",
      "cnt =  122\n",
      " \n",
      "beach_name =  PEBBLY BEACH\n",
      "index =  122\n",
      " \n",
      "cnt =  123\n",
      " \n",
      "beach_name =  PEPPERTREE BEACH\n",
      "index =  123\n",
      " \n",
      "cnt =  124\n",
      " \n",
      "beach_name =  PETTMANS BEACH\n",
      "index =  124\n",
      " \n",
      "cnt =  125\n",
      " \n",
      "beach_name =  PICNIC BEACH\n",
      "index =  125\n",
      " \n",
      "cnt =  126\n",
      " \n",
      "beach_name =  POINT LEO BEACH\n",
      "index =  126\n",
      " \n",
      "cnt =  127\n",
      " \n",
      "beach_name =  POINT LEO SURF BEACH\n",
      "index =  127\n",
      " \n",
      "cnt =  128\n",
      " \n",
      "beach_name =  PORTSEA SURF BEACH\n",
      "index =  128\n",
      " \n",
      "cnt =  129\n",
      " \n",
      "beach_name =  PRINCETOWN BEACH\n",
      "index =  129\n",
      " \n",
      "cnt =  130\n",
      " \n",
      "beach_name =  PUMPHOUSE BEACH\n",
      "index =  130\n",
      " \n",
      "cnt =  131\n",
      " \n",
      "beach_name =  QUARRY BEACH\n",
      "index =  131\n",
      " \n",
      "cnt =  132\n",
      " \n",
      "beach_name =  QUICKS BEACH\n",
      "index =  132\n",
      " \n",
      "cnt =  133\n",
      " \n",
      "beach_name =  RANELAGH BEACH\n",
      "index =  133\n",
      " \n",
      "cnt =  134\n",
      " \n",
      "beach_name =  RED BLUFF BEACH\n",
      "index =  134\n",
      " \n",
      "cnt =  135\n",
      " \n",
      "beach_name =  REDBANK BEACH\n",
      "index =  135\n",
      " \n",
      "cnt =  136\n",
      " \n",
      "beach_name =  REEVES BEACH\n",
      "index =  136\n",
      " \n",
      "cnt =  137\n",
      " \n",
      "beach_name =  RICARDO BEACH\n",
      "index =  137\n",
      " \n",
      "cnt =  138\n",
      " \n",
      "beach_name =  RIPPLESIDE BEACH\n",
      "index =  138\n",
      " \n",
      "cnt =  139\n",
      " \n",
      "beach_name =  RIVERNOOK BEACH\n",
      "index =  139\n",
      " \n",
      "cnt =  140\n",
      " \n",
      "beach_name =  ROBERTSONS BEACH\n",
      "index =  140\n",
      " \n",
      "cnt =  141\n",
      " \n",
      "beach_name =  ROYAL BEACH\n",
      "index =  141\n",
      " \n",
      "cnt =  142\n",
      " \n",
      "beach_name =  RYE OCEAN BEACH\n",
      "index =  142\n",
      " \n",
      "cnt =  143\n",
      " \n",
      "beach_name =  SAFETY BEACH\n",
      "index =  143\n",
      " \n",
      "cnt =  144\n",
      " \n",
      "beach_name =  SAINT ANDREWS BEACH\n",
      "index =  144\n",
      " \n",
      "cnt =  145\n",
      " \n",
      "beach_name =  SAINT HELENS BEACH\n",
      "index =  145\n",
      " \n",
      "cnt =  146\n",
      " \n",
      "beach_name =  SAINT PAULS BEACH\n",
      "index =  146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "cnt =  147\n",
      " \n",
      "beach_name =  SALMON BEACH\n",
      "index =  147\n",
      " \n",
      "cnt =  148\n",
      " \n",
      "beach_name =  SANDRIDGE BEACH\n",
      "index =  148\n",
      " \n",
      "cnt =  149\n",
      " \n",
      "beach_name =  SANDY WATERHOLE BEACH\n",
      "index =  149\n",
      " \n",
      "cnt =  150\n",
      " \n",
      "beach_name =  SCOTTS BEACH\n",
      "index =  150\n",
      " \n",
      "cnt =  151\n",
      " \n",
      "beach_name =  SCOUT BEACH\n",
      "index =  151\n",
      " \n",
      "cnt =  152\n",
      " \n",
      "beach_name =  SECRET BEACH\n",
      "index =  152\n",
      " \n",
      "cnt =  153\n",
      " \n",
      "beach_name =  SHELLEY BEACH\n",
      "index =  153\n",
      " \n",
      "cnt =  154\n",
      " \n",
      "beach_name =  SHELLY BEACH\n",
      "index =  154\n",
      " \n",
      "cnt =  155\n",
      " \n",
      "beach_name =  SHIRE HALL BEACH\n",
      "index =  155\n",
      " \n",
      "cnt =  156\n",
      " \n",
      "beach_name =  SHOREHAM BEACH\n",
      "index =  156\n",
      " \n",
      "cnt =  157\n",
      " \n",
      "beach_name =  SMITH BEACH\n",
      "index =  157\n",
      " \n",
      "cnt =  158\n",
      " \n",
      "beach_name =  SMITHS BEACH\n",
      "index =  158\n",
      " \n",
      "cnt =  159\n",
      " \n",
      "beach_name =  SOMERS BEACH\n",
      "index =  159\n",
      " \n",
      "cnt =  160\n",
      " \n",
      "beach_name =  SORRENTO BACK BEACH\n",
      "index =  160\n",
      " \n",
      "cnt =  161\n",
      " \n",
      "beach_name =  SORRENTO FRONT BEACH\n",
      "index =  161\n",
      " \n",
      "cnt =  162\n",
      " \n",
      "beach_name =  SOUTH BEACH\n",
      "index =  162\n",
      " \n",
      "cnt =  163\n",
      " \n",
      "beach_name =  SOUTHCOMBE BEACH\n",
      "index =  163\n",
      " \n",
      "cnt =  164\n",
      " \n",
      "beach_name =  SQUEAKY BEACH\n",
      "index =  164\n",
      " \n",
      "cnt =  165\n",
      " \n",
      "beach_name =  ST ANDREWS BEACH\n",
      "index =  165\n",
      " \n",
      "cnt =  166\n",
      " \n",
      "beach_name =  ST HELENS BEACH\n",
      "index =  166\n",
      " \n",
      "cnt =  167\n",
      " \n",
      "beach_name =  ST PAULS BEACH\n",
      "index =  167\n",
      " \n",
      "cnt =  168\n",
      " \n",
      "beach_name =  STATION BEACH\n",
      "index =  168\n",
      " \n",
      "cnt =  169\n",
      " \n",
      "beach_name =  STEELES BEACH\n",
      "index =  169\n",
      " \n",
      "cnt =  170\n",
      " \n",
      "beach_name =  SUNNYSIDE BEACH\n",
      "index =  170\n",
      " \n",
      "cnt =  171\n",
      " \n",
      "beach_name =  SUTHERLANDS BEACH\n",
      "index =  171\n",
      " \n",
      "cnt =  172\n",
      " \n",
      "beach_name =  TAYLORS BEACH\n",
      "index =  172\n",
      " \n",
      "cnt =  173\n",
      " \n",
      "beach_name =  TEACHERS BEACH\n",
      "index =  173\n",
      " \n",
      "cnt =  174\n",
      " \n",
      "beach_name =  THE MAHOGANYS\n",
      "index =  174\n",
      " \n",
      "cnt =  175\n",
      " \n",
      "beach_name =  THE WRECK BEACH\n",
      "index =  175\n",
      " \n",
      "cnt =  176\n",
      " \n",
      "beach_name =  THIRTEENTH BEACH\n",
      "index =  176\n",
      " \n",
      "cnt =  177\n",
      " \n",
      "beach_name =  THOMSONS BEACH\n",
      "index =  177\n",
      " \n",
      "cnt =  178\n",
      " \n",
      "beach_name =  THORNY BEACH\n",
      "index =  178\n",
      " \n",
      "cnt =  179\n",
      " \n",
      "beach_name =  THREE MILE BEACH\n",
      "index =  179\n",
      " \n",
      "cnt =  180\n",
      " \n",
      "beach_name =  TIP BEACH\n",
      "index =  180\n",
      " \n",
      "cnt =  181\n",
      " \n",
      "beach_name =  TOORA BEACH\n",
      "index =  181\n",
      " \n",
      "cnt =  182\n",
      " \n",
      "beach_name =  TRUES BEACH\n",
      "index =  182\n",
      " \n",
      "cnt =  183\n",
      " \n",
      "beach_name =  TURRAS BEACH\n",
      "index =  183\n",
      " \n",
      "cnt =  184\n",
      " \n",
      "beach_name =  ULUPNA BEACH\n",
      "index =  184\n",
      " \n",
      "cnt =  185\n",
      " \n",
      "beach_name =  WEISS BEACH\n",
      "index =  185\n",
      " \n",
      "cnt =  186\n",
      " \n",
      "beach_name =  WESTERN BEACH\n",
      "index =  186\n",
      " \n",
      "cnt =  187\n",
      " \n",
      "beach_name =  WESTERN PARK BEACH\n",
      "index =  187\n",
      " \n",
      "cnt =  188\n",
      " \n",
      "beach_name =  WHITES BEACH\n",
      "index =  188\n",
      " \n",
      "cnt =  189\n",
      " \n",
      "beach_name =  WILD DOG BEACH\n",
      "index =  189\n",
      " \n",
      "cnt =  190\n",
      " \n",
      "beach_name =  WILD DOG SHORE\n",
      "index =  190\n",
      " \n",
      "cnt =  191\n",
      " \n",
      "beach_name =  WILLOW BEACH\n",
      "index =  191\n",
      " \n",
      "cnt =  192\n",
      " \n",
      "beach_name =  WILSONS BEACH\n",
      "index =  192\n",
      " \n",
      "cnt =  193\n",
      " \n",
      "beach_name =  WOODSIDE BEACH\n",
      "index =  193\n",
      " \n",
      "cnt =  194\n",
      " \n",
      "beach_name =  WOOLAMAI SURF BEACH\n",
      "index =  194\n",
      " \n",
      "cnt =  195\n",
      " \n",
      "beach_name =  WOOLLEY BEACH\n",
      "index =  195\n",
      " \n",
      "cnt =  196\n",
      " \n",
      "beach_name =  WRECK BEACH\n",
      "index =  196\n",
      " \n",
      "cnt =  197\n",
      " \n",
      "beach_name =  YANAKIE BEACH\n",
      "index =  197\n",
      " \n",
      "cnt =  198\n",
      " \n",
      "beach_name =  ZINETTIS BEACH NO. 1\n",
      "index =  198\n",
      " \n",
      "cnt =  199\n",
      " \n",
      "beach_name =  ZINETTIS BEACH NO. 2\n",
      "index =  199\n",
      " \n",
      "cnt =  200\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# Wall time: 14min 4s\n",
    "# datum_tide_df\n",
    "cnt = 0\n",
    "for index, row in beach_df.loc[:,:].iterrows():\n",
    "#     if index >= 0:\n",
    "    print(\"beach_name = \", row[\"beach_name\"])\n",
    "    print(\"index = \", index)\n",
    "    timestamp_epochs = int(time.mktime(time.strptime(given_date, '%Y-%m-%d')))\n",
    "\n",
    "    url = \"https://tides.p.rapidapi.com/tides\"    \n",
    "    querystring = {\"interval\":\"60\",\n",
    "                   \"duration\":\"1440\",\n",
    "#                    \"duration\": \"7200\",\n",
    "                   \"timestamp\": str(timestamp_epochs),\n",
    "                   \"latitude\":str(row[\"beach_latitude\"]),\n",
    "                   \"longitude\":str(row[\"beach_longitude\"])}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-host': \"tides.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': \"1f79b4df37msh714afcfc6dcaf4ep10f0dfjsn67fa86f634ec\",\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n",
    "        }\n",
    "\n",
    "    response_dict = json.loads(requests.request(\"GET\", url, headers = headers, params = querystring).text)\n",
    "#     print(\"response_dict - \", response_dict)\n",
    "    print(\" \")\n",
    "    if response_dict['status'] == 200:\n",
    "        cnt = cnt + 1\n",
    "        print(\"cnt = \", cnt)\n",
    "\n",
    "#         Updating heights_tide_df \n",
    "#                                          'date',\n",
    "#                                         'beach_id',\n",
    "#                                         'beach_name',\n",
    "#                                         'beach_latitude',\n",
    "#                                         'beach_longitude',\n",
    "#                                         'beach_state',  \n",
    "#                                          'timestamp', \n",
    "#                                          'datetime', \n",
    "#                                          'height', \n",
    "#                                          'state', \n",
    "#                                          'origin_distance',\n",
    "#                                          \"origin_distance_unit\", \n",
    "#                                          \"origin_latitude\", \n",
    "#                                          \"origin_longitude\", \n",
    "#                                          \"timezone\"\n",
    "\n",
    "        heights_tide_row_dict = {}\n",
    "        heights_tide_row_dict[\"date\"] = given_date\n",
    "        heights_tide_row_dict[\"beach_id\"] = row[\"beach_id\"]\n",
    "        heights_tide_row_dict[\"beach_name\"] = row[\"beach_name\"]\n",
    "        heights_tide_row_dict[\"beach_latitude\"] = row[\"beach_latitude\"]\n",
    "        heights_tide_row_dict[\"beach_longitude\"] = row[\"beach_longitude\"]\n",
    "        heights_tide_row_dict[\"beach_state\"] = row[\"beach_state\"]\n",
    "        \n",
    "\n",
    "        heights_tide_row_dict[\"origin_distance\"] = response_dict['origin']['distance']\n",
    "        heights_tide_row_dict[\"origin_distance_unit\"] = response_dict['origin']['unit']\n",
    "        heights_tide_row_dict[\"origin_latitude\"] = response_dict['origin']['latitude']\n",
    "        heights_tide_row_dict[\"origin_longitude\"] = response_dict['origin']['longitude']\n",
    "        heights_tide_row_dict[\"timezone\"] = response_dict[\"timezone\"]\n",
    "\n",
    "        for ht_dict in response_dict['heights']:\n",
    "            heights_tide_row_dict[\"timestamp\"] = ht_dict['timestamp']\n",
    "            heights_tide_row_dict[\"datetime\"] = ht_dict['datetime']\n",
    "            heights_tide_row_dict[\"height\"] = ht_dict['height']\n",
    "            heights_tide_row_dict[\"state\"] = ht_dict['state']\n",
    "\n",
    "            heights_tide_df = heights_tide_df.append(heights_tide_row_dict, \n",
    "                                                 ignore_index = True)\n",
    "\n",
    "#         Updating extremes_tide_df:\n",
    "#                                         'date',\n",
    "#                                         'beach_address',\n",
    "#                                         'beach_name',\n",
    "#                                         'country_state',\n",
    "#                                         'country',\n",
    "#                                         'latitude',\n",
    "#                                         'longitude',    \n",
    "#                                         'timestamp', \n",
    "#                                         'datetime', \n",
    "#                                         'height', \n",
    "#                                         'state'\n",
    "\n",
    "        extremes_tide_row_dict = {}\n",
    "        extremes_tide_row_dict[\"date\"] = given_date\n",
    "        extremes_tide_row_dict[\"beach_id\"] = row[\"beach_id\"]\n",
    "        extremes_tide_row_dict[\"beach_name\"] = row[\"beach_name\"]\n",
    "        extremes_tide_row_dict[\"beach_latitude\"] = row[\"beach_latitude\"]\n",
    "        extremes_tide_row_dict[\"beach_longitude\"] = row[\"beach_longitude\"]\n",
    "        extremes_tide_row_dict[\"beach_state\"] = row[\"beach_state\"] \n",
    "\n",
    "        for extremes_dict in response_dict['extremes']:\n",
    "\n",
    "            extremes_tide_row_dict[\"timestamp\"] = extremes_dict['timestamp']\n",
    "            extremes_tide_row_dict[\"datetime\"] = extremes_dict['datetime']\n",
    "            extremes_tide_row_dict[\"height\"] = extremes_dict['height']\n",
    "            extremes_tide_row_dict[\"state\"] = extremes_dict['state']   \n",
    "\n",
    "            extremes_tide_df = extremes_tide_df.append(extremes_tide_row_dict, \n",
    "                                                 ignore_index = True)\n",
    "\n",
    "        #         Updating datum_tide_df\n",
    "#                                         'date',\n",
    "#                                         'beach_address',\n",
    "#                                         'beach_name',\n",
    "#                                         'country_state',\n",
    "#                                         'country',\n",
    "#                                         'latitude',\n",
    "#                                         'longitude',                \n",
    "#                                         'timestamp', \n",
    "#                                         'datetime', \n",
    "#                                         'datum', \n",
    "#                                         'LAT', \n",
    "#                                         'HAT'\n",
    "        datum_tide_row_dict = {}\n",
    "        datum_tide_row_dict[\"date\"] = given_date\n",
    "        datum_tide_row_dict[\"beach_id\"] = row[\"beach_id\"]\n",
    "        datum_tide_row_dict[\"beach_name\"] = row[\"beach_name\"]\n",
    "        datum_tide_row_dict[\"beach_latitude\"] = row[\"beach_latitude\"]\n",
    "        datum_tide_row_dict[\"beach_longitude\"] = row[\"beach_longitude\"]\n",
    "        datum_tide_row_dict[\"beach_state\"] = row[\"beach_state\"] \n",
    "\n",
    "        datum_tide_row_dict[\"timestamp\"] = response_dict[\"timestamp\"]\n",
    "        datum_tide_row_dict[\"datetime\"] = response_dict[\"datetime\"]\n",
    "        datum_tide_row_dict[\"datum\"] = response_dict[\"datum\"]\n",
    "        datum_tide_row_dict[\"LAT\"] = response_dict['datums'][\"LAT\"]\n",
    "        datum_tide_row_dict[\"HAT\"] = response_dict['datums'][\"HAT\"]\n",
    "\n",
    "        datum_tide_df = datum_tide_df.append(\n",
    "                                            datum_tide_row_dict,\n",
    "                                            ignore_index = True\n",
    "                                            )\n",
    "        print(\" \")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heights_tide_df.shape =  (4800, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"heights_tide_df.shape = \",heights_tide_df.shape)\n",
    "# heights_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# heights_tide_df.to_csv(log_dataset_path + \"heights_tide_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extremes_tide_df.shape =  (820, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"extremes_tide_df.shape = \", extremes_tide_df.shape)\n",
    "# extremes_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# extremes_tide_df.to_csv(log_dataset_path + \"extremes_tide_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVERT UTC TIME to LOCAL TIME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime_in_dif_timezones(from_datetime_str, from_timezone_str, to_timezone_str, \n",
    "                                      datetime_format = '%Y-%m-%dT%H:%M:%S'):\n",
    "#     USE pytz.all_timezones to get all timestamps\n",
    "    from datetime import datetime\n",
    "    import pytz\n",
    "    date_time_obj = datetime.strptime(from_datetime_str, datetime_format)\n",
    "#     print(\"date_time_obj = \", date_time_obj)\n",
    "    \n",
    "    old_timezone = pytz.timezone(from_timezone_str)\n",
    "    new_timezone = pytz.timezone(to_timezone_str)\n",
    "    \n",
    "    new_timezone_timestamp = old_timezone.localize(date_time_obj).astimezone(new_timezone).strftime(\"%Y-%m-%dT%H:%M:%S\") \n",
    "#     print(\"new_timezone_timestamp\", new_timezone_timestamp)\n",
    "    return str(new_timezone_timestamp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_tide_df[\"datetime\"] = heights_tide_df[\"datetime\"].apply(lambda x: convert_datetime_in_dif_timezones(from_datetime_str = x, \n",
    "                                                                                  from_timezone_str = 'UTC', \n",
    "                                                                                  to_timezone_str ='Australia/Melbourne', \n",
    "                                                                                datetime_format = '%Y-%m-%dT%H:%M:%S+00:00'))\n",
    "\n",
    "extremes_tide_df[\"datetime\"] = extremes_tide_df[\"datetime\"].apply(lambda x: convert_datetime_in_dif_timezones(from_datetime_str = x, \n",
    "                                                                                  from_timezone_str = 'UTC', \n",
    "                                                                                  to_timezone_str ='Australia/Melbourne', \n",
    "                                                                                datetime_format = '%Y-%m-%dT%H:%M:%S+00:00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get date from Date time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_tide_df['date'] = heights_tide_df['datetime'].apply(lambda x: x.split(\"T\")[0])\n",
    "extremes_tide_df['date'] = extremes_tide_df['datetime'].apply(lambda x: x.split(\"T\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create date_coordinates column which will be used as PK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_tide_df[\"date_beach_name\"] = heights_tide_df[\n",
    "                                                     ['date', 'beach_name']\n",
    "                                                     ].apply(lambda x: '|'.join(x.astype(str).values), axis=1)\n",
    "# heights_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_tide_df[\"date_beach_name\"] = extremes_tide_df[\n",
    "                                                     ['date', 'beach_name']\n",
    "                                                     ].apply(lambda x: '|'.join(x.astype(str).values), axis=1)\n",
    "# extremes_tide_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TIDE_HEIGHT_24HR_TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_table_query = \"\"\" \n",
    "                            CREATE TABLE IF NOT EXISTS TIDE_HEIGHT_TABLE (\n",
    "                                tide_height_id SERIAL PRIMARY KEY ,\n",
    "                                date DATE,\n",
    "                                beach_id INTEGER NOT NULL,\n",
    "                                beach_name TEXT,\n",
    "                                beach_latitude REAL,\n",
    "                                beach_longitude REAL,\n",
    "                                beach_state TEXT,\n",
    "                                timestamp INTEGER,\n",
    "                                datetime TEXT,\n",
    "                                height REAL,\n",
    "                                state TEXT,\n",
    "                                origin_distance REAL,\n",
    "                                origin_distance_unit TEXT,\n",
    "                                origin_latitude REAL,\n",
    "                                origin_longitude REAL,\n",
    "                                timezone TEXT,\n",
    "                                date_beach_name TEXT,\n",
    "                                FOREIGN KEY (beach_id) REFERENCES beach_table(beach_id) ON DELETE CASCADE\n",
    "                                ); \n",
    "                            \"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERTION TIDE_HEIGHT_24HR_TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Wall time: 12min 51s\n",
    "import psycopg2 as ps\n",
    "\n",
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "fill_question_mark_str = str(tuple([\"%s\"  for i in heights_tide_df.columns.tolist()])).replace(\"'\", \"\")\n",
    "fill_question_mark_str\n",
    "\n",
    "for row in heights_tide_df.itertuples():\n",
    "    data_tuple = tuple(row[1:])\n",
    "\n",
    "#     print(\"data_tuple = \", data_tuple)\n",
    "#     print(\" \")\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "                        INSERT INTO TIDE_HEIGHT_TABLE\n",
    "                        (\n",
    "                                date,\n",
    "                                beach_id,\n",
    "                                beach_name,\n",
    "                                beach_latitude,\n",
    "                                beach_longitude,\n",
    "                                beach_state,\n",
    "                                timestamp,\n",
    "                                datetime,\n",
    "                                height,\n",
    "                                state,\n",
    "                                origin_distance,\n",
    "                                origin_distance_unit,\n",
    "                                origin_latitude,\n",
    "                                origin_longitude,\n",
    "                                timezone,\n",
    "                                date_beach_name\n",
    "                         ) VALUES  \n",
    "                         \"\"\" + fill_question_mark_str + \" ;\"\n",
    "                , data_tuple)    \n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE EXTREMES_HEIGHT_24HR_TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_table_query = \"\"\" \n",
    "                            CREATE TABLE IF NOT EXISTS EXTREMES_HEIGHT_TABLE (\n",
    "                                extremes_height_id SERIAL PRIMARY KEY ,\n",
    "                                date DATE,\n",
    "                                beach_id INTEGER NOT NULL,\n",
    "                                beach_name TEXT,\n",
    "                                beach_latitude REAL,\n",
    "                                beach_longitude REAL,\n",
    "                                beach_state TEXT,\n",
    "                                timestamp INTEGER,\n",
    "                                datetime TEXT,\n",
    "                                height REAL,\n",
    "                                state TEXT,\n",
    "                                date_beach_name TEXT,\n",
    "                                FOREIGN KEY (beach_id) REFERENCES beach_table(beach_id) ON DELETE CASCADE\n",
    "                                ); \n",
    "                            \"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERTION EXTREMES_HEIGHT_24HR_TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Wall time: 12min 51s\n",
    "import psycopg2 as ps\n",
    "\n",
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "fill_question_mark_str = str(tuple([\"%s\"  for i in extremes_tide_df.columns.tolist()])).replace(\"'\", \"\")\n",
    "fill_question_mark_str\n",
    "\n",
    "for row in extremes_tide_df.itertuples():\n",
    "    data_tuple = tuple(row[1:])\n",
    "\n",
    "#     print(\"data_tuple = \", data_tuple)\n",
    "#     print(\" \")\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "                        INSERT INTO EXTREMES_HEIGHT_TABLE\n",
    "                        (\n",
    "                            date,\n",
    "                            beach_id,\n",
    "                            beach_name,\n",
    "                            beach_latitude,\n",
    "                            beach_longitude,\n",
    "                            beach_state,\n",
    "                            timestamp,\n",
    "                            datetime,\n",
    "                            height,\n",
    "                            state,\n",
    "                            date_beach_name\n",
    "                         ) VALUES  \n",
    "                         \"\"\" + fill_question_mark_str + \" ;\"\n",
    "                , data_tuple)    \n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGGREGATES TIDES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_beach_loc_attri_lst = [ \n",
    "                            \"date\",\n",
    "                            \"beach_id\",\n",
    "                            \"beach_name\",\n",
    "                            \"beach_latitude\",\n",
    "                            \"beach_longitude\",\n",
    "                            \"beach_state\",\n",
    "                            \"date_beach_name\",\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEIGHTS FALL TIDES AGG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_fall_heights_tide_df.shape =  (200, 14)\n"
     ]
    }
   ],
   "source": [
    "agg_ops_lst = ['max','min','mean','median','std','var','sem']\n",
    "numeric_features = [\"height\"]\n",
    "agg_dict = dict(zip(numeric_features, [agg_ops_lst for i in range(len(numeric_features))]))\n",
    "# agg_dict\n",
    "\n",
    "agg_fall_heights_tide_df = heights_tide_df.loc[heights_tide_df['state'] == \"FALLING\",:\n",
    "                                              ].groupby([\n",
    "                                                        'date_beach_name',\n",
    "                                                        ]).agg(agg_dict)\n",
    "\n",
    "\n",
    "agg_fall_heights_tide_df.columns = [\"_fall_\".join(x) for x in agg_fall_heights_tide_df.columns.ravel()]\n",
    "\n",
    "agg_fall_heights_tide_df =  pd.merge(\n",
    "                               agg_fall_heights_tide_df, \n",
    "                               heights_tide_df[req_beach_loc_attri_lst],\n",
    "                               left_on = \"date_beach_name\",\n",
    "                               right_on = \"date_beach_name\",\n",
    "                               how = \"inner\"\n",
    "                                    )\n",
    "\n",
    "agg_fall_heights_tide_df.drop_duplicates(inplace = True)\n",
    "\n",
    "agg_fall_heights_tide_df.reset_index(inplace = True, \n",
    "                                     drop = True)\n",
    "\n",
    "print(\"agg_fall_heights_tide_df.shape = \", agg_fall_heights_tide_df.shape)\n",
    "# agg_fall_heights_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# agg_fall_heights_tide_df.to_csv(log_dataset_path + \"agg_fall_heights_tide_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEIGHTS RISE TIDES AGG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_rise_heights_tide_df.shape =  (200, 14)\n"
     ]
    }
   ],
   "source": [
    "agg_ops_lst = ['max','min','mean','median','std','var','sem']\n",
    "numeric_features = [\"height\"]\n",
    "agg_dict = dict(zip(numeric_features, [agg_ops_lst for i in range(len(numeric_features))]))\n",
    "# agg_dict\n",
    "\n",
    "agg_rise_heights_tide_df = heights_tide_df.loc[heights_tide_df['state'] == \"RISING\",:\n",
    "                                              ].groupby([\n",
    "                                                        'date_beach_name',\n",
    "                                                        ]\n",
    "                                                       ).agg(agg_dict)\n",
    "\n",
    "agg_rise_heights_tide_df.columns = [\"_rise_\".join(x) for x in agg_rise_heights_tide_df.columns.ravel()]\n",
    "\n",
    "agg_rise_heights_tide_df =  pd.merge(\n",
    "                               agg_rise_heights_tide_df, \n",
    "                               heights_tide_df[req_beach_loc_attri_lst],\n",
    "                               left_on = \"date_beach_name\",\n",
    "                               right_on = \"date_beach_name\",\n",
    "                               how = \"inner\"\n",
    "                                    )\n",
    "\n",
    "agg_rise_heights_tide_df.drop_duplicates(inplace = True)\n",
    "\n",
    "agg_rise_heights_tide_df.reset_index(inplace = True, \n",
    "                                     drop = True)\n",
    "\n",
    "print(\"agg_rise_heights_tide_df.shape = \", agg_rise_heights_tide_df.shape)\n",
    "# agg_rise_heights_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# agg_rise_heights_tide_df.to_csv(log_dataset_path + \"agg_rise_heights_tide_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTREMES HIGH TIDES AGG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_high_tide_extremes_tide_df.shape =  (200, 10)\n"
     ]
    }
   ],
   "source": [
    "agg_ops_lst = ['max','min','mean']\n",
    "numeric_features = [\"height\"]\n",
    "agg_dict = dict(zip(numeric_features, [agg_ops_lst for i in range(len(numeric_features))]))\n",
    "# agg_dict\n",
    "\n",
    "agg_high_tide_extremes_tide_df = extremes_tide_df.loc[extremes_tide_df['state'] == \"HIGH TIDE\",:\n",
    "                                              ].groupby([\n",
    "                                                        'date_beach_name',\n",
    "                                                        ]).agg(agg_dict)\n",
    "\n",
    "agg_high_tide_extremes_tide_df.columns = [\"_high_tide_\".join(x) for x in agg_high_tide_extremes_tide_df.columns.ravel()]\n",
    "\n",
    "agg_high_tide_extremes_tide_df =  pd.merge(\n",
    "                               agg_high_tide_extremes_tide_df, \n",
    "                               extremes_tide_df[req_beach_loc_attri_lst],\n",
    "                               left_on = \"date_beach_name\",\n",
    "                               right_on = \"date_beach_name\",\n",
    "                               how = \"inner\"\n",
    "                                    )\n",
    "\n",
    "agg_high_tide_extremes_tide_df.drop_duplicates(inplace = True)\n",
    "\n",
    "agg_high_tide_extremes_tide_df.reset_index(inplace = True, \n",
    "                                     drop = True)\n",
    "\n",
    "print(\"agg_high_tide_extremes_tide_df.shape = \", agg_high_tide_extremes_tide_df.shape)\n",
    "# agg_high_tide_extremes_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# agg_high_tide_extremes_tide_df.to_csv(log_dataset_path + \"agg_high_tide_extremes_tide_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTREMES LOW TIDES AGG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_low_tide_extremes_tide_df.shape =  (200, 10)\n"
     ]
    }
   ],
   "source": [
    "agg_ops_lst = ['max','min','mean']\n",
    "numeric_features = [\"height\"]\n",
    "agg_dict = dict(zip(numeric_features, [agg_ops_lst for i in range(len(numeric_features))]))\n",
    "# agg_dict\n",
    "\n",
    "agg_low_tide_extremes_tide_df = extremes_tide_df.loc[extremes_tide_df['state'] == \"LOW TIDE\",:\n",
    "                                              ].groupby(['date_beach_name']).agg(agg_dict)\n",
    "\n",
    "agg_low_tide_extremes_tide_df.columns = [\"_low_tide_\".join(x) for x in agg_low_tide_extremes_tide_df.columns.ravel()]\n",
    "\n",
    "agg_low_tide_extremes_tide_df =  pd.merge(\n",
    "                               agg_low_tide_extremes_tide_df, \n",
    "                               extremes_tide_df[req_beach_loc_attri_lst],\n",
    "                               left_on = \"date_beach_name\",\n",
    "                               right_on = \"date_beach_name\",\n",
    "                               how = \"inner\"\n",
    "                                    )\n",
    "\n",
    "agg_low_tide_extremes_tide_df.drop_duplicates(inplace = True)\n",
    "\n",
    "agg_low_tide_extremes_tide_df.reset_index(inplace = True, \n",
    "                                     drop = True)\n",
    "\n",
    "print(\"agg_low_tide_extremes_tide_df.shape = \", agg_low_tide_extremes_tide_df.shape)\n",
    "# agg_low_tide_extremes_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# agg_low_tide_extremes_tide_df.to_csv(log_dataset_path + \"agg_low_tide_extremes_tide_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF TIDE API PROCESSING:\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joing WEATHER AND TIDE AGG DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# agg_rise_heights_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_df_lst = [\n",
    "                agg_rise_heights_tide_df, agg_fall_heights_tide_df,\n",
    "                agg_high_tide_extremes_tide_df, agg_low_tide_extremes_tide_df,\n",
    "#                 agg_datum_tide_df,\n",
    "              ]\n",
    "join_weather_tide_df = agg_weather_df.copy()\n",
    "for df in tide_df_lst:\n",
    "    join_weather_tide_df = pd.merge(\n",
    "                               join_weather_tide_df, \n",
    "                               df.drop(['date', 'beach_name', 'beach_name', 'beach_state', \n",
    "                                        'beach_latitude','beach_longitude'], axis = 1, inplace = False),\n",
    "                               left_on = \"date_beach_name\",\n",
    "                               right_on = \"date_beach_name\",\n",
    "                               how = \"inner\")\n",
    "# drop_col_lst = []\n",
    "# for col in join_weather_tide_df.columns.tolist():\n",
    "#     if col.endswith(\"_x\")|col.endswith(\"_y\"):\n",
    "#         drop_col_lst.append(col)\n",
    "        \n",
    "# join_weather_tide_df.drop(drop_col_lst, \n",
    "#                           axis=1, \n",
    "#                           inplace=True)\n",
    "\n",
    "        \n",
    "# join_weather_tide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join_weather_tide_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_month_season_month_day_func(date):\n",
    "    month = date.split(\"-\")[1]\n",
    "    month_day = date.split(\"-\")[2]\n",
    "    if (int(month) == 9) | (int(month) == 10) | (int(month) == 11):\n",
    "        season = \"spring\"\n",
    "    elif (int(month) == 12) | (int(month) == 1) | (int(month) == 2):\n",
    "        season = \"summer\"\n",
    "    elif (int(month) == 3) | (int(month) == 4) | (int(month) == 5):\n",
    "        season = \"autumn\"\n",
    "    elif (int(month) == 6) | (int(month) == 7) | (int(month) == 8):\n",
    "        season = \"winter\"\n",
    "    return month, season, month_day\n",
    "join_weather_tide_df['month'], join_weather_tide_df['season'], join_weather_tide_df['month_day'] = zip(*join_weather_tide_df.apply(lambda x: \n",
    "                                                                                        get_month_season_month_day_func(\n",
    "                                                                                            x['date']), \n",
    "                                                                                        axis = 1))\n",
    "# join_weather_tide_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML MODEL INFERENCE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_lst = [\n",
    "#     Using Weather features\n",
    "    'temperature_max',\n",
    " 'temperature_min',\n",
    " 'temperature_mean',\n",
    " 'temperature_median',\n",
    " 'temperature_std',\n",
    " 'temperature_var',\n",
    " 'temperature_sem',\n",
    " 'apparentTemperature_max',\n",
    " 'apparentTemperature_min',\n",
    " 'apparentTemperature_mean',\n",
    " 'apparentTemperature_median',\n",
    " 'apparentTemperature_std',\n",
    " 'apparentTemperature_var',\n",
    " 'apparentTemperature_sem',\n",
    " 'dewPoint_max',\n",
    " 'dewPoint_min',\n",
    " 'dewPoint_mean',\n",
    " 'dewPoint_median',\n",
    " 'dewPoint_std',\n",
    " 'dewPoint_var',\n",
    " 'dewPoint_sem',\n",
    " 'humidity_max',\n",
    " 'humidity_min',\n",
    " 'humidity_mean',\n",
    " 'humidity_median',\n",
    " 'humidity_std',\n",
    " 'humidity_var',\n",
    " 'humidity_sem',\n",
    " 'windSpeed_max',\n",
    " 'windSpeed_min',\n",
    " 'windSpeed_mean',\n",
    " 'windSpeed_median',\n",
    " 'windSpeed_std',\n",
    " 'windSpeed_var',\n",
    " 'windSpeed_sem',\n",
    " 'windBearing_max',\n",
    " 'windBearing_min',\n",
    " 'windBearing_mean',\n",
    " 'windBearing_median',\n",
    " 'windBearing_std',\n",
    " 'windBearing_var',\n",
    " 'windBearing_sem',\n",
    " 'uvIndex_max',\n",
    " 'uvIndex_min',\n",
    " 'uvIndex_mean',\n",
    " 'uvIndex_median',\n",
    " 'uvIndex_std',\n",
    " 'uvIndex_var',\n",
    " 'uvIndex_sem',\n",
    " 'cloudCover_max',\n",
    " 'cloudCover_min',\n",
    " 'cloudCover_mean',\n",
    " 'cloudCover_median',\n",
    " 'cloudCover_std',\n",
    " 'cloudCover_var',\n",
    " 'cloudCover_sem',\n",
    "# Tides Features                        \n",
    " 'height_fall_max',\n",
    " 'height_fall_min',\n",
    " 'height_fall_mean',\n",
    " 'height_fall_median',\n",
    " 'height_fall_std',\n",
    " 'height_fall_var',\n",
    " 'height_fall_sem',\n",
    " 'height_rise_max',\n",
    " 'height_rise_min',\n",
    " 'height_rise_mean',\n",
    " 'height_rise_median',\n",
    " 'height_rise_std',\n",
    " 'height_rise_var',\n",
    " 'height_rise_sem',\n",
    " 'height_high_tide_max',\n",
    " 'height_high_tide_min',\n",
    " 'height_high_tide_mean',\n",
    " 'height_low_tide_max',\n",
    " 'height_low_tide_min',\n",
    " 'height_low_tide_mean',\n",
    "#  'LAT_datum_mean',\n",
    "#  'HAT_datum_mean',\n",
    " 'beach_latitude',\n",
    " 'beach_longitude'\n",
    "]\n",
    "cat_features_lst = [\n",
    " 'month',\n",
    " 'month_day',\n",
    " 'season']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHARK ATTACK PREDICTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1c3c1ff65c8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'loss_function':'Logloss', # objective function\n",
    "          'eval_metric':'Accuracy', # metric\n",
    "          'verbose': 200, # output to stdout info about training process every 200 iterations\n",
    "          'random_seed': 100\n",
    "         }\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "model.load_model('catboost_model_rand_search_tide_weather_shark_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_weather_tide_df[\"shark_attack_percentage\"] = 0.0\n",
    "for index, row in join_weather_tide_df[numeric_features_lst+cat_features_lst].iterrows():\n",
    "#     print(model.predict_proba(row.values)[1])\n",
    "    join_weather_tide_df.loc[index, \"shark_attack_percentage\"] = round(float(model.predict_proba(row.values)[1])*100.0, 3)\n",
    "#     join_weather_tide_df.loc[index, \"shark_attack_percentage\"] = model.predict_proba(row.values)[1]\n",
    "\n",
    "# join_weather_tide_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHARK SIGHTING PREDICTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV clean addresses with Coordinates CSV as Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File for_ml_join_shark_weather_tide_df.csv does not exist: 'for_ml_join_shark_weather_tide_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-30b97a6bc5f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# dataset_path = r\"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\\\\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjoin_shark_weather_tide_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"for_ml_join_shark_weather_tide_df.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# raw_shark_df = pd.read_excel(dataset_path + \"shark_file_geolocation_checkpoint.xlsx\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"join_shark_weather_tide_df.shape = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_shark_weather_tide_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File for_ml_join_shark_weather_tide_df.csv does not exist: 'for_ml_join_shark_weather_tide_df.csv'"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\\\\"\n",
    "# dataset_path = r\"\"\n",
    "join_shark_weather_tide_df = pd.read_csv(\"for_ml_join_shark_weather_tide_df.csv\")\n",
    "# raw_shark_df = pd.read_excel(dataset_path + \"shark_file_geolocation_checkpoint.xlsx\")\n",
    "print(\"join_shark_weather_tide_df.shape = \", join_shark_weather_tide_df.shape)\n",
    "join_shark_weather_tide_df.rename(columns = {\n",
    "                                            \"lat\":\"beach_latitude\",\n",
    "                                            \"lng\":\"beach_longitude\"}, inplace = True)\n",
    "# join_shark_weather_tide_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Cosine Similarity: Comparing point with distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Wall time: 2min 36s\n",
    "threshold = 0.90\n",
    "join_weather_tide_df['shark_sighting_percentage'] = 0.0\n",
    "for index_o, row_o in join_weather_tide_df[numeric_features_lst].iterrows():\n",
    "    cos_sim_lst = []\n",
    "    for index_i, row_i in join_shark_weather_tide_df[numeric_features_lst].iterrows():\n",
    "    \n",
    "        cosine_similarity_score = cosine_similarity(\n",
    "                                                    X = row_o.values.reshape(1, -1), \n",
    "                                                    Y = row_i.values.reshape(1, -1), \n",
    "                                                    dense_output=True).flatten()[0]\n",
    "        \n",
    "        cos_sim_lst.append(cosine_similarity_score)\n",
    "    \n",
    "    no_vals_above = len([i for i in cos_sim_lst if i > threshold])\n",
    "    \n",
    "    percent_vals_above = round((no_vals_above/float(join_shark_weather_tide_df.shape[0]))*100.0, 3)\n",
    "    \n",
    "    join_weather_tide_df.loc[index_o, 'shark_sighting_percentage'] = percent_vals_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_2_level_func(percent):\n",
    "    if (percent > 0) & (percent <= 25):\n",
    "        return \"Low\"\n",
    "    elif (percent > 25) & (percent <= 50):\n",
    "        return \"Moderately Low\"\n",
    "    elif (percent > 50) & (percent <= 75):\n",
    "        return \"Moderately High\"\n",
    "    elif (percent > 75) & (percent <= 100):\n",
    "        return \"High\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_weather_tide_df[\"shark_sighting_level\"] = join_weather_tide_df[\"shark_sighting_percentage\"].apply(percent_2_level_func)\n",
    "join_weather_tide_df[\"shark_attack_level\"] = join_weather_tide_df[\"shark_attack_percentage\"].apply(percent_2_level_func)\n",
    "# join_weather_tide_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dataset_path = \"D:\\Monash_University_Stuff\\Final_Semester\\IE\\Surfers_Bible_Code_Commit\\Datasets\\Daily_weather_tide_log\\\\\"\n",
    "# join_weather_tide_df.to_csv(log_dataset_path + \"join_weather_tide_df\"+\"_10_05\"+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join_weather_tide_df\n",
    "join_weather_tide_df = join_weather_tide_df.loc[:,~join_weather_tide_df.columns.duplicated()]\n",
    "join_weather_tide_df.drop(['beach_id_y'], axis=1, inplace=True)\n",
    "join_weather_tide_df.rename(columns = {\"beach_id_x\": \"beach_id\"}, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE join_weather_tide_TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_table_query = \"\"\" \n",
    "                            CREATE TABLE IF NOT EXISTS SHARK_PREDICTION_TABLE (\n",
    "                                shark_prediction_id SERIAL PRIMARY KEY ,\n",
    "                                date_beach_name TEXT,\n",
    "                                temperature_max REAL,\n",
    "                                temperature_min REAL,\n",
    "                                temperature_mean REAL,\n",
    "                                temperature_median REAL,\n",
    "                                temperature_std REAL,\n",
    "                                temperature_var REAL,\n",
    "                                temperature_sem REAL,\n",
    "                                apparentTemperature_max REAL,\n",
    "                                apparentTemperature_min REAL,\n",
    "                                apparentTemperature_mean REAL,\n",
    "                                apparentTemperature_median REAL,\n",
    "                                apparentTemperature_std REAL,\n",
    "                                apparentTemperature_var REAL,\n",
    "                                apparentTemperature_sem REAL,\n",
    "                                dewPoint_max REAL,\n",
    "                                dewPoint_min REAL,\n",
    "                                dewPoint_mean REAL,\n",
    "                                dewPoint_median REAL,\n",
    "                                dewPoint_std REAL,\n",
    "                                dewPoint_var REAL,\n",
    "                                dewPoint_sem REAL,\n",
    "                                humidity_max REAL,\n",
    "                                humidity_min REAL,\n",
    "                                humidity_mean REAL,\n",
    "                                humidity_median REAL,\n",
    "                                humidity_std REAL,\n",
    "                                humidity_var REAL,\n",
    "                                humidity_sem REAL,\n",
    "                                windSpeed_max REAL,\n",
    "                                windSpeed_min REAL,\n",
    "                                windSpeed_mean REAL,\n",
    "                                windSpeed_median REAL,\n",
    "                                windSpeed_std REAL, \n",
    "                                windSpeed_var REAL,\n",
    "                                windSpeed_sem REAL,\n",
    "                                windBearing_max REAL,\n",
    "                                windBearing_min REAL,\n",
    "                                windBearing_mean REAL,\n",
    "                                windBearing_median REAL,\n",
    "                                windBearing_std REAL,\n",
    "                                windBearing_var REAL,\n",
    "                                windBearing_sem REAL,\n",
    "                                uvIndex_max REAL,\n",
    "                                uvIndex_min REAL,\n",
    "                                uvIndex_mean REAL,\n",
    "                                uvIndex_median REAL,\n",
    "                                uvIndex_std REAL,\n",
    "                                uvIndex_var REAL,\n",
    "                                uvIndex_sem REAL,\n",
    "                                cloudCover_max REAL,\n",
    "                                cloudCover_min REAL,\n",
    "                                cloudCover_mean REAL,\n",
    "                                cloudCover_median REAL,\n",
    "                                cloudCover_std REAL,\n",
    "                                cloudCover_var REAL,\n",
    "                                cloudCover_sem REAL,\n",
    "                                date DATE,\n",
    "                                beach_name TEXT,\n",
    "                                beach_latitude REAL,\n",
    "                                beach_longitude REAL,\n",
    "                                beach_state TEXT,\n",
    "                                height_rise_max REAL,\n",
    "                                height_rise_min REAL,\n",
    "                                height_rise_mean REAL,\n",
    "                                height_rise_median REAL,\n",
    "                                height_rise_std REAL,\n",
    "                                height_rise_var REAL,\n",
    "                                height_rise_sem REAL,\n",
    "                                beach_id INTEGER,\n",
    "                                height_fall_max REAL,\n",
    "                                height_fall_min REAL,\n",
    "                                height_fall_mean REAL,\n",
    "                                height_fall_median REAL,\n",
    "                                height_fall_std REAL,\n",
    "                                height_fall_var REAL,\n",
    "                                height_fall_sem REAL,\n",
    "                                height_high_tide_max REAL,\n",
    "                                height_high_tide_min REAL,\n",
    "                                height_high_tide_mean REAL,\n",
    "                                height_low_tide_max REAL,\n",
    "                                height_low_tide_min REAL,\n",
    "                                height_low_tide_mean REAL,\n",
    "                                month TEXT,\n",
    "                                season TEXT,\n",
    "                                month_day TEXT,\n",
    "                                shark_attack_percentage REAL,\n",
    "                                shark_sighting_percentage REAL,\n",
    "                                shark_sighting_level TEXT,\n",
    "                                shark_attack_level TEXT,\n",
    "                                FOREIGN KEY (beach_id) REFERENCES beach_table(beach_id) ON DELETE CASCADE\n",
    "                                ); \n",
    "                            \"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERTION join_weather_tide_TABLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Wall time: 34 s\n",
    "import psycopg2 as ps\n",
    "\n",
    "# define credentials \n",
    "credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "               'POSTGRES_PORT' : 5432, # change to your port\n",
    "               'POSTGRES_USERNAME' : 'ai_postgres', # change to your username\n",
    "               'POSTGRES_PASSWORD' : 'postgres2309', # change to your password\n",
    "               'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "# create connection and cursor    \n",
    "conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                  database=credentials['POSTGRES_DBNAME'],\n",
    "                  user=credentials['POSTGRES_USERNAME'],\n",
    "                  password=credentials['POSTGRES_PASSWORD'],\n",
    "                  port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "fill_question_mark_str = str(tuple([\"%s\"  for i in join_weather_tide_df.columns.tolist()])).replace(\"'\", \"\")\n",
    "fill_question_mark_str\n",
    "\n",
    "for row in join_weather_tide_df.itertuples():\n",
    "    data_tuple = tuple(row[1:])\n",
    "\n",
    "    print(\"data_tuple = \", data_tuple)\n",
    "    print(\" \")\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "                        INSERT INTO SHARK_PREDICTION_TABLE\n",
    "                        (\n",
    "                            date_beach_name,\n",
    "                            temperature_max,\n",
    "                            temperature_min,\n",
    "                            temperature_mean,\n",
    "                            temperature_median,\n",
    "                            temperature_std,\n",
    "                            temperature_var,\n",
    "                            temperature_sem,\n",
    "                            apparentTemperature_max,\n",
    "                            apparentTemperature_min,\n",
    "                            apparentTemperature_mean,\n",
    "                            apparentTemperature_median,\n",
    "                            apparentTemperature_std,\n",
    "                            apparentTemperature_var,\n",
    "                            apparentTemperature_sem,\n",
    "                            dewPoint_max,\n",
    "                            dewPoint_min,\n",
    "                            dewPoint_mean,\n",
    "                            dewPoint_median,\n",
    "                            dewPoint_std,\n",
    "                            dewPoint_var,\n",
    "                            dewPoint_sem,\n",
    "                            humidity_max,\n",
    "                            humidity_min,\n",
    "                            humidity_mean,\n",
    "                            humidity_median,\n",
    "                            humidity_std,\n",
    "                            humidity_var,\n",
    "                            humidity_sem,\n",
    "                            windSpeed_max,\n",
    "                            windSpeed_min,\n",
    "                            windSpeed_mean,\n",
    "                            windSpeed_median,\n",
    "                            windSpeed_std,\n",
    "                            windSpeed_var,\n",
    "                            windSpeed_sem,\n",
    "                            windBearing_max,\n",
    "                            windBearing_min,\n",
    "                            windBearing_mean,\n",
    "                            windBearing_median,\n",
    "                            windBearing_std,\n",
    "                            windBearing_var,\n",
    "                            windBearing_sem,\n",
    "                            uvIndex_max,\n",
    "                            uvIndex_min,\n",
    "                            uvIndex_mean,\n",
    "                            uvIndex_median,\n",
    "                            uvIndex_std,\n",
    "                            uvIndex_var,\n",
    "                            uvIndex_sem,\n",
    "                            cloudCover_max,\n",
    "                            cloudCover_min,\n",
    "                            cloudCover_mean,\n",
    "                            cloudCover_median,\n",
    "                            cloudCover_std,\n",
    "                            cloudCover_var,\n",
    "                            cloudCover_sem,\n",
    "                            date,\n",
    "                            beach_name,\n",
    "                            beach_latitude,\n",
    "                            beach_longitude,\n",
    "                            beach_state,\n",
    "                            height_rise_max,\n",
    "                            height_rise_min,\n",
    "                            height_rise_mean,\n",
    "                            height_rise_median,\n",
    "                            height_rise_std,\n",
    "                            height_rise_var,\n",
    "                            height_rise_sem,\n",
    "                            beach_id,\n",
    "                            height_fall_max,\n",
    "                            height_fall_min,\n",
    "                            height_fall_mean,\n",
    "                            height_fall_median,\n",
    "                            height_fall_std,\n",
    "                            height_fall_var,\n",
    "                            height_fall_sem,\n",
    "                            height_high_tide_max,\n",
    "                            height_high_tide_min,\n",
    "                            height_high_tide_mean,\n",
    "                            height_low_tide_max,\n",
    "                            height_low_tide_min,\n",
    "                            height_low_tide_mean,\n",
    "                            month,\n",
    "                            season,\n",
    "                            month_day,\n",
    "                            shark_attack_percentage,\n",
    "                            shark_sighting_percentage,\n",
    "                            shark_sighting_level,\n",
    "                            shark_attack_level\n",
    "                         ) VALUES  \n",
    "                         \"\"\" + fill_question_mark_str + \" ;\"\n",
    "                , data_tuple)    \n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
